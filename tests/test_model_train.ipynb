{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing packages\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src/')\n",
    "#!{sys.executable} -m pip install segmentation-models-pytorch plotly kaleido albumentations\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms.v2 import RandomHorizontalFlip, RandomVerticalFlip, Compose\n",
    "import albumentations as A\n",
    "\n",
    "from typing import Callable, List\n",
    "from fusion_tools.dataset import ClassificationDataset\n",
    "from fusion_tools.utils.shapes import load_histomics\n",
    "from math import floor\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellClassificationModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_size: int = 2):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3,6,5)\n",
    "        self.pool = torch.nn.MaxPool2d(2,2)\n",
    "        self.conv2 = torch.nn.Conv2d(6,16,5)\n",
    "        self.fc1 = torch.nn.LazyLinear(120)\n",
    "        self.fc2 = torch.nn.Linear(120,84)\n",
    "        self.fc3 = torch.nn.Linear(84,self.output_size)\n",
    "        \n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            self.conv1,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.pool,\n",
    "            self.conv2,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.pool\n",
    "        )\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.fc2,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.fc3\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.conv_layers(input)\n",
    "        output = torch.flatten(output,1)\n",
    "        output = torch.nn.Softmax(dim=1)(self.linear_layers(output))        \n",
    "        return output\n",
    "\n",
    "\n",
    "def cell_percentages(inp:list):\n",
    "\n",
    "    if len(inp)>0:\n",
    "        return torch.from_numpy(np.array([inp.count(0.0)/len(inp), inp.count(1.0)/len(inp)]))\n",
    "    else:\n",
    "        return torch.from_numpy(np.array([1.0, 0.0]))\n",
    "\n",
    "def normalize_01(inp:np.ndarray):\n",
    "    out = (inp - np.min(inp))/ np.ptp(inp)\n",
    "    return out\n",
    "\n",
    "def train(train_data, val_data, model, optimizer, loss, output_dir):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    loss.to(device)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    epoch_num = 10\n",
    "    save_step = 50\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "    with tqdm(total = epoch_num, position = 0, leave = True, file = sys.stdout) as pbar:\n",
    "        for i in range(0,epoch_num):\n",
    "            pbar.update(1)\n",
    "            for step, (train_imgs,train_labels) in enumerate(train_data):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pbar.set_description(f'Epoch: {i}/{epoch_num}, Train Step: {step}, Train/Val Loss: {round(train_loss,4)}/{round(val_loss,4)}')\n",
    "\n",
    "                #train_imgs, train_labels = next(iter(train_data))\n",
    "                train_imgs = train_imgs.to(device)\n",
    "                train_labels = train_labels.to(device)\n",
    "\n",
    "                train_pred = model(train_imgs)\n",
    "\n",
    "                train_loss = loss(train_pred, train_labels)\n",
    "                train_loss.backward()\n",
    "                train_loss = train_loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "                losses.append({\n",
    "                    'step': i*step, 'loss': train_loss, 'Train/Val': 'train'\n",
    "                })\n",
    "\n",
    "                if step%save_step==0:\n",
    "                    with torch.no_grad():\n",
    "                        model.eval()\n",
    "\n",
    "                        for val_step, (val_imgs, val_labels) in enumerate(val_data):\n",
    "                            pbar.set_description(f'Epoch: {i}/{epoch_num}, Val Step: {val_step}, Train/Val Loss: {round(train_loss,4)}/{round(val_loss,4)}')\n",
    "                            \n",
    "                            val_pred = model(val_imgs)\n",
    "                            val_loss = loss(val_pred, val_labels)\n",
    "                            val_loss = val_loss.item()\n",
    "\n",
    "                            losses.append(\n",
    "                                {'step': i*val_step, 'loss': val_loss, 'Train/Val': 'val'}\n",
    "                            )\n",
    "\n",
    "                    torch.save(model.state_dict(), output_dir+'Segmentation_Model.pth')\n",
    "                    loss_df = pd.DataFrame.from_records(losses)\n",
    "                    loss_df.to_csv(output_dir+'Loss.csv')\n",
    "\n",
    "        torch.save(model.state_dict(), output_dir+'Segmentation_Model.pth')\n",
    "        loss_df = pd.DataFrame.from_records(losses)\n",
    "        loss_df.to_csv(output_dir+'Loss.csv')\n",
    "        vis(loss_df,output_dir)\n",
    "        pbar.close()\n",
    "\n",
    "def test():\n",
    "    pass\n",
    "\n",
    "def vis(loss_df, output_dir):\n",
    "    \n",
    "    plot = px.line(\n",
    "        data_frame=loss_df,\n",
    "        x = 'step',\n",
    "        y = 'loss',\n",
    "        color = 'Train/Val'\n",
    "    )\n",
    "\n",
    "    plot.write_image(output_dir+'Loss_Plot.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset construction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:08<00:00, 193.09it/s]\n",
      "100%|██████████| 1600/1600 [00:07<00:00, 222.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "slides = [\n",
    "    \"C:\\\\Users\\\\samuelborder\\\\Desktop\\\\HIVE_Stuff\\\\FUSION\\\\Test Upload\\\\Xenium_Data\\\\40775.tif\"\n",
    "]\n",
    "annotations = load_histomics('C:\\\\Users\\\\samuelborder\\\\Desktop\\\\HIVE_Stuff\\\\FUSION\\\\Test Upload\\\\Xenium_Data\\\\Cells.json')[0]\n",
    "\n",
    "# Splitting the data into training and validation sets:\n",
    "total_anns = len(annotations['features'])\n",
    "train_test_split = 0.75\n",
    "train_annotations = [{\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': annotations['features'][:floor(train_test_split*total_anns)],\n",
    "    'properties': {'name': 'Train Cells'}\n",
    "}]\n",
    "\n",
    "val_annotations = [{\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': annotations['features'][floor(train_test_split*total_anns):],\n",
    "    'properties': {'name': 'Validation Cells'}\n",
    "}]\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Image augmentations\n",
    "train_transforms = Compose([\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Converts list of labels per cell to proportions of each cell type\n",
    "label_transform = lambda imm_list: cell_percentages(imm_list)\n",
    "\n",
    "print('Starting dataset construction')\n",
    "train_data = ClassificationDataset(\n",
    "    slides = slides,\n",
    "    annotations = train_annotations,\n",
    "    label_property = 'Main_Cell_Types --> IMM',\n",
    "    transforms = train_transforms,\n",
    "    label_transforms = label_transform,\n",
    "    use_cache = False,\n",
    "    use_parallel=False,\n",
    "    patch_mode = 'centered_bbox',\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "val_data = ClassificationDataset(\n",
    "    slides = slides,\n",
    "    annotations = val_annotations,\n",
    "    label_property = 'Main_Cell_Types --> IMM',\n",
    "    transforms = val_transforms,\n",
    "    label_transforms = label_transform,\n",
    "    use_cache = False,\n",
    "    use_parallel=False,\n",
    "    patch_mode = 'centered_bbox',\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "print('Datasets prepared!')\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = False)\n",
    "val_dataloader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "model = CellClassificationModel(\n",
    "    output_size = 2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params = model.parameters(), lr = 5e-7, weight_decay = 0.00001)\n",
    "])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Epoch: 9/10, Step: 99, Train/Val Loss: 0.5434/0.5863: 100%|██████████| 10/10 [03:44<00:00, 22.41s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Starting Training!')\n",
    "train(\n",
    "    train_data = train_dataloader,\n",
    "    val_data = val_dataloader,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss = loss,\n",
    "    output_dir = './outputs/'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
