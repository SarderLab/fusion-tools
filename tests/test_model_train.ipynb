{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing packages\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src/')\n",
    "#!{sys.executable} -m pip install segmentation-models-pytorch plotly kaleido==0.1.0 albumentations\n",
    "#!{sys.executable} -m pip install nbformat\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from torchvision.transforms.v2 import RandomHorizontalFlip, RandomVerticalFlip, ElasticTransform, ColorJitter, Compose\n",
    "import albumentations as A\n",
    "\n",
    "from typing import Callable, List\n",
    "from fusion_tools.dataset import ClassificationDataset\n",
    "from fusion_tools.utils.shapes import load_histomics\n",
    "from math import floor\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellClassificationModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_size: int = 2,\n",
    "                 simple: bool = True):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.simple = simple\n",
    "        self.fc1 = torch.nn.LazyLinear(120)\n",
    "        self.fc2 = torch.nn.Linear(120,84)\n",
    "        self.fc3 = torch.nn.Linear(84,self.output_size)\n",
    "        \n",
    "        if self.simple:\n",
    "            self.conv1 = torch.nn.Conv2d(3,6,5)\n",
    "            self.pool = torch.nn.MaxPool2d(2,2)\n",
    "            self.conv2 = torch.nn.Conv2d(6,16,5)\n",
    "\n",
    "            self.conv_layers = torch.nn.Sequential(\n",
    "                self.conv1,\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                self.pool,\n",
    "                self.conv2,\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                self.pool\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            model_weights = torchvision.models.EfficientNet_V2_S_Weights\n",
    "            self.conv_layers = torchvision.models.efficientnet_v2_s(weights = model_weights.DEFAULT)\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.fc2,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.fc3\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.conv_layers(input)\n",
    "        output = torch.flatten(output,1)\n",
    "        output = torch.nn.Sigmoid()(self.linear_layers(output))        \n",
    "        return output\n",
    "\n",
    "\n",
    "def cell_percentages(inp:list):\n",
    "    if len(inp)>0:\n",
    "        return torch.from_numpy(np.array([sum([-1*(i-1) for i in inp])/len(inp), sum(inp)/len(inp)]))\n",
    "    else:\n",
    "        return torch.from_numpy(np.array([1.0, 0.0]))\n",
    "\n",
    "def train(train_data, val_data, model, optimizer, loss, output_dir):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    loss.to(device)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    epoch_num = 5\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    losses = []\n",
    "    train_step_count = 0\n",
    "    with tqdm(total = epoch_num, position = 0, leave = True, file = sys.stdout) as pbar:\n",
    "        for i in range(0,epoch_num):\n",
    "            for step, (train_imgs,train_labels) in enumerate(train_data):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pbar.set_description(f'Epoch: {i}/{epoch_num}, Train Step: {step}, Train/Val Loss: {round(train_loss,4)}/{round(val_loss,4)}')\n",
    "\n",
    "                train_imgs = train_imgs.to(device)\n",
    "                train_labels = train_labels.to(device)\n",
    "\n",
    "                train_pred = model(train_imgs)\n",
    "\n",
    "                train_loss = loss(train_pred, train_labels)\n",
    "                train_loss.backward()\n",
    "                train_loss = train_loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "                losses.append({\n",
    "                    'step': train_step_count+step, 'loss': train_loss, 'Train/Val': 'train'\n",
    "                })\n",
    "\n",
    "                # Performing validation\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    val_imgs, val_labels = next(iter(val_data))\n",
    "\n",
    "                    val_imgs = val_imgs.to(device)\n",
    "                    val_labels = val_labels.to(device)\n",
    "\n",
    "                    val_pred = model(val_imgs)\n",
    "                    val_loss = loss(val_pred, val_labels)\n",
    "                    val_loss = val_loss.item()\n",
    "\n",
    "                    losses.append(\n",
    "                        {'step': train_step_count+step, 'loss': val_loss, 'Train/Val': 'val'}\n",
    "                    )\n",
    "\n",
    "            train_step_count+=step\n",
    "            torch.save(model.state_dict(), output_dir+'Classification_Model.pth')\n",
    "            loss_df = pd.DataFrame.from_records(losses)\n",
    "            loss_df.to_csv(output_dir+'Loss.csv')\n",
    "            vis_loss(loss_df,output_dir)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "        pbar.update(1)\n",
    "        torch.save(model.state_dict(), output_dir+'Classification_Model.pth')\n",
    "        loss_df = pd.DataFrame.from_records(losses)\n",
    "        loss_df.to_csv(output_dir+'Loss.csv')\n",
    "        vis_loss(loss_df,output_dir)\n",
    "        pbar.close()\n",
    "\n",
    "def vis_loss(loss_df, output_dir):\n",
    "    \n",
    "    plot = px.line(\n",
    "        data_frame=loss_df,\n",
    "        x = 'step',\n",
    "        y = 'loss',\n",
    "        color = 'Train/Val'\n",
    "    )\n",
    "\n",
    "    plot.write_image(output_dir+'Loss_Plot.png')\n",
    "\n",
    "def test(model_path, output_size, holdout_data, n):\n",
    "\n",
    "    model = CellClassificationModel(\n",
    "        output_size = output_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        model.load_state_dict(torch.load(model_path,weights_only=True))\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        model.load_state_dict(torch.load(model_path,weights_only=True,map_location = torch.device('cpu')))\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_dataloader = iter(DataLoader(holdout_data,batch_size=1,shuffle=False))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(n):\n",
    "            image,gt = next(test_dataloader)\n",
    "            pred = model(image.to(device)).detach().numpy()\n",
    "\n",
    "            image = np.moveaxis(np.squeeze(image.detach().numpy()),source=0,destination=-1)\n",
    "\n",
    "            plot = go.Figure(\n",
    "                px.imshow(image)\n",
    "            )\n",
    "            plot.show()\n",
    "\n",
    "            print(f'Predicted: {pred}, GT: {gt.numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides = [\n",
    "    \"C:\\\\Users\\\\samuelborder\\\\Desktop\\\\HIVE_Stuff\\\\FUSION\\\\Test Upload\\\\Xenium_Data\\\\40775.tif\"\n",
    "]\n",
    "annotations = load_histomics('C:\\\\Users\\\\samuelborder\\\\Desktop\\\\HIVE_Stuff\\\\FUSION\\\\Test Upload\\\\Xenium_Data\\\\Cells.json')[0]\n",
    "\n",
    "# Splitting the data into training and validation sets:\n",
    "total_anns = len(annotations['features'])\n",
    "train_test_split = 0.75\n",
    "train_annotations = [{\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': annotations['features'][:floor(train_test_split*total_anns)],\n",
    "    'properties': {'name': 'Train Cells'}\n",
    "}]\n",
    "\n",
    "val_annotations = [{\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': annotations['features'][floor(train_test_split*total_anns):],\n",
    "    'properties': {'name': 'Validation Cells'}\n",
    "}]\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Image augmentations (Normalization means and std are optimized for ImageNet pre-trained models)\n",
    "train_transforms = Compose([\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    ColorJitter(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean = [0.485, 0.456, 0.406], std = [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean = [0.485,0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Converts list of labels per cell to proportions of each cell type\n",
    "label_transform = lambda imm_list: cell_percentages(imm_list)\n",
    "\n",
    "print('Starting dataset construction')\n",
    "train_data = ClassificationDataset(\n",
    "    slides = slides,\n",
    "    annotations = train_annotations,\n",
    "    label_property = 'Main_Cell_Types --> IMM',\n",
    "    transforms = train_transforms,\n",
    "    label_transforms = label_transform,\n",
    "    use_cache = False,\n",
    "    use_parallel=False,\n",
    "    patch_mode = 'centered_bbox',\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "val_data = ClassificationDataset(\n",
    "    slides = slides,\n",
    "    annotations = val_annotations,\n",
    "    label_property = 'Main_Cell_Types --> IMM',\n",
    "    transforms = val_transforms,\n",
    "    label_transforms = label_transform,\n",
    "    use_cache = False,\n",
    "    use_parallel=False,\n",
    "    patch_mode = 'centered_bbox',\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "print('Datasets prepared!')\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CellClassificationModel(\n",
    "    output_size = 2,\n",
    "    simple = False\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params = model.parameters(), lr = 5e-5, weight_decay = 0.00001)\n",
    "])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting Training!')\n",
    "print(f'Number of steps per epoch: {round(len(train_data)/batch_size)}')\n",
    "train(\n",
    "    train_data = train_dataloader,\n",
    "    val_data = val_dataloader,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss = loss,\n",
    "    output_dir = './outputs/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting Testing!')\n",
    "test(\n",
    "    model_path = './outputs/Classification_Model.pth',\n",
    "    output_size = 2,\n",
    "    holdout_data = val_data,\n",
    "    n = 10\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
